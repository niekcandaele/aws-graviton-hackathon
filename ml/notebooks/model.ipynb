{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "## Introduction\n",
    "We always look at a round from the point of view of team_1.\n",
    "\n",
    "## Features: \n",
    "- **target**: team_1 won the round\n",
    "- **kills**: Amount of players killed by team_1\n",
    "- **deaths**: Amount of players that died from team_1\n",
    "- **equipment_value_ratio**: Total equipment value compared to equipment value of team_2. *This is better than saving the equipment values from both the teams. $650 in a pistol round is normal. $650 in round 10 can probably be considered as a saving round.*\n",
    "- **first_kill**: Did team_1 make the first kill. Making the first kill results in a higher chance of winning the round.\n",
    "\n",
    "# Features to implement\n",
    "- **defuse_kit_count**: Amount of defusekits. \n",
    "  - **values**: [None,0,1,2,3,4,5] (None when team_1 are terrorists)\n",
    "- **alive_ratio_on_bomb_planted**: Amount of players alive from team_1 compared to players alive from team_2 when the bomb is planted.\n",
    "- **distance_from_bomb_on_plant**: Average distance from team_1 when bomb is planted. (Maybe they are already saving)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed rounds: 30\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering\n",
    "from feature_engineering import db\n",
    "from feature_engineering import parser\n",
    "from dataclasses import make_dataclass,fields\n",
    "from bson.objectid import ObjectId\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "collections = db.get_collections()\n",
    "Round = make_dataclass(\"Round\", [(\"kills\", int),(\"deaths\", int),(\"first_blood\", int),(\"round_winstreak\", int)])\n",
    "\n",
    "parsed_rounds = []\n",
    "target = []\n",
    "matches = collections[\"matches\"].find({}).limit(1)\n",
    "\n",
    "\n",
    "for match in matches:\n",
    "  round_winstreak = 0\n",
    "  team_1_id = match[\"teams\"][0]\n",
    "\n",
    "  # ROUND\n",
    "  for round_id in match[\"rounds\"]:\n",
    "\n",
    "    # Check if round exists\n",
    "    if collections[\"rounds\"].find_one({ \"_id\": ObjectId(round_id)}) is None:\n",
    "      continue\n",
    "\n",
    "    round = parser.Round(round_id,team_1_id)\n",
    "    (kills, deaths) = round.kills_and_deaths()\n",
    "\n",
    "    if round.is_win() :\n",
    "      target.append(1)\n",
    "      round_winstreak+= 1\n",
    "    else:\n",
    "      target.append(0)\n",
    "      round_winstreak=0\n",
    "\n",
    "    parsed_rounds.append(Round(kills=kills,deaths=deaths,first_blood=round.is_first_blood(), round_winstreak = round_winstreak))\n",
    "\n",
    "print(\"Parsed rounds:\", len(parsed_rounds))\n",
    "data = pd.DataFrame(parsed_rounds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should how diverse our dataset is. If in 80% of our games team_1 wins.\n",
    "# We will learn the model that it can always pick team_1 and get an accuracy of 80%. We don't want that :)\n",
    "\n",
    "# Split the data in training and testing data\n",
    "train_X,test_X, train_Y, test_Y = train_test_split(data,target,test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "With SVM we try to find the maximum margin separator between our two classes (team_1_wins, team_2_wins). This is the line the furtest from the nearest training data points. SVM calculates the distance to the closest datapoint for each possible line and picks the one with the highest distance. This makes an SVM a **maximum margin estimator. \n",
    "\n",
    "In most real probelms, it is not possible to find the perfect separating plane. Sometimes there are datapoints that are not closer to the other class. To handle this we allow the SVM to soften the margin. Which means we allow some of the points to creep into the margin if that allows a better fit. This transforms our SVM into a soft-margin classifier since we are allowing for a few mistakes. This is typically called C.\n",
    "\n",
    "C is a hyperparameter that needs to be tuned based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00220819, 0.0012115 , 0.00123787, 0.00132589, 0.00154986,\n",
      "       0.00176582, 0.00157566, 0.00143147, 0.00147333, 0.00128088,\n",
      "       0.00123096, 0.00115118, 0.00113769, 0.0012157 , 0.00135016,\n",
      "       0.00140662, 0.00115099, 0.0011343 , 0.00127907, 0.00140271,\n",
      "       0.00116911, 0.00126424, 0.00116768, 0.0013135 , 0.00138488,\n",
      "       0.00139008, 0.00130105, 0.00115328, 0.00126309, 0.00135283,\n",
      "       0.00123591, 0.00118618, 0.00112829, 0.00113707, 0.00125613,\n",
      "       0.00127192, 0.0011622 , 0.0012001 , 0.00114665, 0.00117373,\n",
      "       0.00123019, 0.00121107, 0.00112801, 0.00113645, 0.00119061,\n",
      "       0.00125928, 0.00134754, 0.00133452, 0.00122886, 0.00118709,\n",
      "       0.00132031, 0.00128927, 0.00124593, 0.00126185, 0.00120659,\n",
      "       0.0012188 , 0.0012939 , 0.00129857, 0.00119004, 0.00113635,\n",
      "       0.00120335, 0.00148253, 0.00123358, 0.00118155, 0.0011796 ,\n",
      "       0.0011652 , 0.0012084 , 0.00124116, 0.00122709, 0.00133328,\n",
      "       0.00111718, 0.0012846 , 0.00123725, 0.00121298, 0.00115924,\n",
      "       0.00120931, 0.0012609 , 0.00118828, 0.00146723, 0.00136299,\n",
      "       0.00126166, 0.00125875, 0.00150328, 0.00204182, 0.00130377,\n",
      "       0.00129967, 0.00132618, 0.00142655, 0.00142446, 0.00135465,\n",
      "       0.00125804, 0.00116158, 0.00135298, 0.00119495, 0.00113139,\n",
      "       0.00113215, 0.0012372 , 0.00127335, 0.00117145, 0.00114956,\n",
      "       0.00117302, 0.00113358, 0.00115356, 0.00130434, 0.00130019,\n",
      "       0.00113654, 0.00133648, 0.00128303, 0.00139594, 0.00131044,\n",
      "       0.00117912, 0.0012197 , 0.00126419, 0.00134807, 0.00135536,\n",
      "       0.00123315, 0.00124397, 0.00123668, 0.00133181, 0.00129042,\n",
      "       0.00115371, 0.00116487, 0.00117083, 0.00127101, 0.00144668,\n",
      "       0.00120554, 0.00114884, 0.00114794, 0.0012053 , 0.00121112,\n",
      "       0.00130653, 0.00117435, 0.00122676, 0.00110536, 0.0014977 ,\n",
      "       0.00134592, 0.00128012, 0.00122552, 0.0012053 , 0.00117149,\n",
      "       0.00149927, 0.00139847, 0.00125794, 0.00121374, 0.00122643,\n",
      "       0.00146284, 0.00131927]), 'std_fit_time': array([1.22309987e-03, 5.23786898e-05, 5.46838882e-05, 9.58532120e-05,\n",
      "       3.41230168e-04, 4.45262092e-04, 1.12673039e-04, 1.61858157e-04,\n",
      "       1.95621687e-04, 1.20183171e-04, 4.96506333e-05, 3.38935637e-05,\n",
      "       2.13564499e-05, 1.20662981e-04, 1.51412880e-04, 3.66868060e-04,\n",
      "       4.19623743e-05, 2.25582785e-05, 1.25173741e-04, 3.17128101e-04,\n",
      "       5.01204623e-05, 1.21867824e-04, 4.29933158e-05, 1.23519086e-04,\n",
      "       4.01705735e-04, 1.06807223e-04, 1.45066764e-04, 6.61569929e-05,\n",
      "       2.49392188e-04, 1.88879129e-04, 7.51836876e-05, 6.07740884e-05,\n",
      "       2.46726254e-05, 3.08087732e-05, 9.60613989e-05, 1.05030396e-04,\n",
      "       4.04538371e-05, 9.98730391e-05, 3.11603506e-05, 9.80499414e-05,\n",
      "       1.11009124e-04, 6.80646586e-05, 2.15314022e-05, 3.72203704e-05,\n",
      "       7.33739753e-05, 1.52453229e-04, 1.47826518e-04, 2.34355281e-04,\n",
      "       1.29544151e-04, 9.02669239e-05, 2.22736522e-04, 1.49095062e-04,\n",
      "       1.16768200e-04, 1.41994035e-04, 1.83499082e-04, 1.07156354e-04,\n",
      "       1.23449263e-04, 2.95963517e-04, 1.53997260e-04, 2.47153490e-05,\n",
      "       8.12891144e-05, 3.57117078e-04, 6.85666300e-05, 6.28861985e-05,\n",
      "       5.05052718e-05, 6.62595044e-05, 1.95217948e-04, 1.06811460e-04,\n",
      "       1.05404679e-04, 1.99961957e-04, 2.99924129e-05, 1.30613958e-04,\n",
      "       1.32155451e-04, 7.60603248e-05, 1.81839460e-05, 5.08059643e-05,\n",
      "       8.65772154e-05, 4.08644159e-05, 9.87558420e-05, 1.07630861e-04,\n",
      "       6.70219010e-05, 9.96480826e-05, 3.38448904e-04, 4.25604558e-04,\n",
      "       8.70805183e-05, 5.81106637e-05, 1.67106329e-04, 2.61264845e-04,\n",
      "       2.01880577e-04, 6.85462993e-05, 1.62659674e-04, 4.54040626e-05,\n",
      "       3.10598944e-04, 5.31503411e-05, 4.00425689e-05, 3.53566312e-05,\n",
      "       1.32977342e-04, 1.95378136e-04, 1.98541846e-05, 4.85383222e-05,\n",
      "       5.65612089e-05, 3.84440182e-05, 6.46007184e-05, 2.28803015e-04,\n",
      "       1.96157419e-04, 5.60639654e-05, 2.06286919e-04, 2.07207150e-04,\n",
      "       2.57841994e-04, 8.58965727e-05, 3.98182154e-05, 5.37737024e-05,\n",
      "       1.57301677e-04, 2.14832704e-04, 5.73933295e-05, 3.39236714e-05,\n",
      "       7.59610124e-05, 1.02361623e-04, 3.06012526e-04, 1.36727399e-04,\n",
      "       7.69422228e-05, 1.04506389e-04, 9.17010546e-05, 1.97604045e-04,\n",
      "       4.12511448e-04, 7.93752134e-05, 8.01426384e-05, 4.82681696e-05,\n",
      "       1.63133553e-04, 8.67507419e-05, 2.28051428e-04, 8.43537736e-05,\n",
      "       9.84858178e-05, 2.07626310e-05, 1.81850739e-04, 1.49303676e-04,\n",
      "       9.96774903e-05, 5.37861746e-05, 5.28299420e-05, 9.68360591e-05,\n",
      "       1.80742645e-04, 1.72474156e-04, 1.92021228e-04, 8.91967719e-05,\n",
      "       1.48683607e-04, 2.39940867e-04, 2.15315216e-04]), 'mean_score_time': array([0.00128422, 0.0009203 , 0.00094934, 0.00107036, 0.00100074,\n",
      "       0.00127168, 0.00140314, 0.00109305, 0.00107293, 0.00092745,\n",
      "       0.00092626, 0.00089598, 0.00088177, 0.00115733, 0.00111423,\n",
      "       0.00112858, 0.00088344, 0.00088058, 0.00092893, 0.00091386,\n",
      "       0.00088325, 0.00090952, 0.00091505, 0.0009892 , 0.00092349,\n",
      "       0.00107613, 0.00100031, 0.00088415, 0.00090694, 0.00097876,\n",
      "       0.00094318, 0.000876  , 0.00088096, 0.00088139, 0.00091434,\n",
      "       0.00092034, 0.00087914, 0.00091   , 0.00092158, 0.00094376,\n",
      "       0.00092263, 0.00090008, 0.00093145, 0.00096197, 0.00087657,\n",
      "       0.00090532, 0.00103951, 0.00094042, 0.00094867, 0.0009594 ,\n",
      "       0.00092487, 0.00089989, 0.0010035 , 0.00097561, 0.00097666,\n",
      "       0.00090404, 0.00100861, 0.00091667, 0.00093093, 0.00087595,\n",
      "       0.00095258, 0.00107212, 0.00094156, 0.0009306 , 0.00089092,\n",
      "       0.00088048, 0.00091052, 0.00092826, 0.00096221, 0.00089626,\n",
      "       0.00086308, 0.00097651, 0.00089698, 0.00091405, 0.00089869,\n",
      "       0.00093384, 0.00093122, 0.00106611, 0.00113916, 0.00101895,\n",
      "       0.00095515, 0.00094271, 0.00119858, 0.00140877, 0.00099144,\n",
      "       0.00105257, 0.00093732, 0.0011013 , 0.00103698, 0.00099497,\n",
      "       0.00094509, 0.00094528, 0.00103803, 0.00094905, 0.00092111,\n",
      "       0.00086269, 0.00088878, 0.00090275, 0.00089045, 0.00088186,\n",
      "       0.00090375, 0.00094485, 0.00094304, 0.00099549, 0.00097709,\n",
      "       0.00093937, 0.00096273, 0.00102634, 0.00115647, 0.00100837,\n",
      "       0.00091372, 0.00092034, 0.00094643, 0.00099592, 0.00097995,\n",
      "       0.00094738, 0.00094166, 0.00088534, 0.00088916, 0.00091567,\n",
      "       0.0008873 , 0.0009079 , 0.00086994, 0.00090237, 0.00092983,\n",
      "       0.00090151, 0.00087042, 0.00088372, 0.0009232 , 0.00097098,\n",
      "       0.00092177, 0.00087461, 0.00091105, 0.00089898, 0.00131183,\n",
      "       0.00091481, 0.00092664, 0.00093694, 0.00090556, 0.00093923,\n",
      "       0.00102515, 0.00106225, 0.00100112, 0.00093269, 0.00091662,\n",
      "       0.00097971, 0.00093403]), 'std_score_time': array([1.76899555e-04, 3.31718993e-05, 4.10629614e-05, 9.42426875e-05,\n",
      "       5.81912500e-05, 4.03608232e-04, 2.67032359e-04, 2.20100130e-04,\n",
      "       8.24275337e-05, 3.21350746e-05, 4.07669278e-05, 2.83519692e-05,\n",
      "       1.96475426e-05, 3.21921217e-04, 2.51014010e-04, 2.31028986e-04,\n",
      "       2.00036456e-05, 2.42074592e-05, 7.96605532e-05, 4.92720706e-05,\n",
      "       1.72240552e-05, 3.86359937e-05, 4.06809451e-05, 1.69625059e-04,\n",
      "       5.18531853e-05, 1.56780664e-04, 1.10315285e-04, 4.56905056e-05,\n",
      "       3.75186312e-05, 6.54873647e-05, 4.40616628e-05, 2.33325928e-05,\n",
      "       2.34534090e-05, 3.25485984e-05, 1.64297909e-05, 3.86392304e-05,\n",
      "       1.33961542e-05, 4.21032360e-05, 2.52766875e-05, 1.13506035e-04,\n",
      "       7.28647745e-05, 2.62639033e-05, 7.39688637e-05, 1.48586498e-04,\n",
      "       1.84336883e-05, 3.13820442e-05, 1.67875870e-04, 9.89730171e-05,\n",
      "       1.35814658e-04, 1.72425727e-04, 8.51196934e-05, 2.46564928e-05,\n",
      "       1.76599266e-04, 1.67201982e-04, 1.82847659e-04, 4.14100609e-05,\n",
      "       1.28608789e-04, 8.73455047e-05, 6.97574790e-05, 2.35593268e-05,\n",
      "       1.41221875e-04, 2.03857751e-04, 5.20647224e-05, 5.40089182e-05,\n",
      "       2.88127250e-05, 3.24554160e-05, 4.44958314e-05, 5.87343770e-05,\n",
      "       1.33088523e-04, 4.83244289e-05, 9.62691592e-06, 1.34951605e-04,\n",
      "       1.87830266e-05, 5.19980809e-05, 2.55971410e-05, 2.75686115e-05,\n",
      "       3.65881722e-05, 2.68349049e-04, 9.72785201e-05, 6.20613041e-05,\n",
      "       5.54410917e-05, 3.51384016e-05, 2.59646191e-04, 3.94725454e-04,\n",
      "       5.94768298e-05, 1.34556180e-04, 5.69768728e-05, 9.88511606e-05,\n",
      "       1.66022935e-04, 1.63259977e-04, 1.57350482e-04, 1.29161042e-04,\n",
      "       2.15480564e-04, 1.27014472e-04, 1.19480073e-04, 7.09606751e-06,\n",
      "       2.29032785e-05, 4.98778505e-05, 7.81402117e-06, 3.16694550e-05,\n",
      "       4.99498247e-05, 1.50649831e-04, 1.46218101e-04, 1.57606086e-04,\n",
      "       7.58760751e-05, 1.68668499e-04, 1.08412470e-04, 1.64125203e-04,\n",
      "       3.09764025e-04, 9.61710450e-05, 4.89265132e-05, 6.50889533e-05,\n",
      "       6.95174939e-05, 1.13524142e-04, 4.16045271e-05, 4.40471082e-05,\n",
      "       1.11328212e-04, 1.62507055e-05, 4.33577411e-05, 4.39393475e-05,\n",
      "       1.40683933e-05, 7.70637301e-05, 2.66079407e-05, 6.80736441e-05,\n",
      "       6.58304740e-05, 1.72404166e-05, 1.57344702e-05, 2.10352755e-05,\n",
      "       9.36255401e-05, 1.66697565e-04, 4.77793212e-05, 2.54403237e-05,\n",
      "       3.45028508e-05, 4.34462766e-05, 2.51597531e-04, 2.79269483e-05,\n",
      "       3.07626865e-05, 4.23989487e-05, 3.47899685e-05, 1.10393168e-04,\n",
      "       5.97690984e-05, 1.69656262e-04, 1.80969596e-04, 8.67637935e-05,\n",
      "       3.94406885e-05, 1.15370787e-04, 6.00469581e-05]), 'param_C': masked_array(data=[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
      "                   7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 12,\n",
      "                   12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16,\n",
      "                   17, 17, 17, 18, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21,\n",
      "                   21, 22, 22, 22, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26,\n",
      "                   26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30, 30,\n",
      "                   31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 34, 34, 35, 35,\n",
      "                   35, 36, 36, 36, 37, 37, 37, 38, 38, 38, 39, 39, 39, 40,\n",
      "                   40, 40, 41, 41, 41, 42, 42, 42, 43, 43, 43, 44, 44, 44,\n",
      "                   45, 45, 45, 46, 46, 46, 47, 47, 47, 48, 48, 48, 49, 49,\n",
      "                   49],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel': masked_array(data=['rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
      "                   'rbf', 'linear', 'sigmoid'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 1, 'kernel': 'rbf'}, {'C': 1, 'kernel': 'linear'}, {'C': 1, 'kernel': 'sigmoid'}, {'C': 2, 'kernel': 'rbf'}, {'C': 2, 'kernel': 'linear'}, {'C': 2, 'kernel': 'sigmoid'}, {'C': 3, 'kernel': 'rbf'}, {'C': 3, 'kernel': 'linear'}, {'C': 3, 'kernel': 'sigmoid'}, {'C': 4, 'kernel': 'rbf'}, {'C': 4, 'kernel': 'linear'}, {'C': 4, 'kernel': 'sigmoid'}, {'C': 5, 'kernel': 'rbf'}, {'C': 5, 'kernel': 'linear'}, {'C': 5, 'kernel': 'sigmoid'}, {'C': 6, 'kernel': 'rbf'}, {'C': 6, 'kernel': 'linear'}, {'C': 6, 'kernel': 'sigmoid'}, {'C': 7, 'kernel': 'rbf'}, {'C': 7, 'kernel': 'linear'}, {'C': 7, 'kernel': 'sigmoid'}, {'C': 8, 'kernel': 'rbf'}, {'C': 8, 'kernel': 'linear'}, {'C': 8, 'kernel': 'sigmoid'}, {'C': 9, 'kernel': 'rbf'}, {'C': 9, 'kernel': 'linear'}, {'C': 9, 'kernel': 'sigmoid'}, {'C': 10, 'kernel': 'rbf'}, {'C': 10, 'kernel': 'linear'}, {'C': 10, 'kernel': 'sigmoid'}, {'C': 11, 'kernel': 'rbf'}, {'C': 11, 'kernel': 'linear'}, {'C': 11, 'kernel': 'sigmoid'}, {'C': 12, 'kernel': 'rbf'}, {'C': 12, 'kernel': 'linear'}, {'C': 12, 'kernel': 'sigmoid'}, {'C': 13, 'kernel': 'rbf'}, {'C': 13, 'kernel': 'linear'}, {'C': 13, 'kernel': 'sigmoid'}, {'C': 14, 'kernel': 'rbf'}, {'C': 14, 'kernel': 'linear'}, {'C': 14, 'kernel': 'sigmoid'}, {'C': 15, 'kernel': 'rbf'}, {'C': 15, 'kernel': 'linear'}, {'C': 15, 'kernel': 'sigmoid'}, {'C': 16, 'kernel': 'rbf'}, {'C': 16, 'kernel': 'linear'}, {'C': 16, 'kernel': 'sigmoid'}, {'C': 17, 'kernel': 'rbf'}, {'C': 17, 'kernel': 'linear'}, {'C': 17, 'kernel': 'sigmoid'}, {'C': 18, 'kernel': 'rbf'}, {'C': 18, 'kernel': 'linear'}, {'C': 18, 'kernel': 'sigmoid'}, {'C': 19, 'kernel': 'rbf'}, {'C': 19, 'kernel': 'linear'}, {'C': 19, 'kernel': 'sigmoid'}, {'C': 20, 'kernel': 'rbf'}, {'C': 20, 'kernel': 'linear'}, {'C': 20, 'kernel': 'sigmoid'}, {'C': 21, 'kernel': 'rbf'}, {'C': 21, 'kernel': 'linear'}, {'C': 21, 'kernel': 'sigmoid'}, {'C': 22, 'kernel': 'rbf'}, {'C': 22, 'kernel': 'linear'}, {'C': 22, 'kernel': 'sigmoid'}, {'C': 23, 'kernel': 'rbf'}, {'C': 23, 'kernel': 'linear'}, {'C': 23, 'kernel': 'sigmoid'}, {'C': 24, 'kernel': 'rbf'}, {'C': 24, 'kernel': 'linear'}, {'C': 24, 'kernel': 'sigmoid'}, {'C': 25, 'kernel': 'rbf'}, {'C': 25, 'kernel': 'linear'}, {'C': 25, 'kernel': 'sigmoid'}, {'C': 26, 'kernel': 'rbf'}, {'C': 26, 'kernel': 'linear'}, {'C': 26, 'kernel': 'sigmoid'}, {'C': 27, 'kernel': 'rbf'}, {'C': 27, 'kernel': 'linear'}, {'C': 27, 'kernel': 'sigmoid'}, {'C': 28, 'kernel': 'rbf'}, {'C': 28, 'kernel': 'linear'}, {'C': 28, 'kernel': 'sigmoid'}, {'C': 29, 'kernel': 'rbf'}, {'C': 29, 'kernel': 'linear'}, {'C': 29, 'kernel': 'sigmoid'}, {'C': 30, 'kernel': 'rbf'}, {'C': 30, 'kernel': 'linear'}, {'C': 30, 'kernel': 'sigmoid'}, {'C': 31, 'kernel': 'rbf'}, {'C': 31, 'kernel': 'linear'}, {'C': 31, 'kernel': 'sigmoid'}, {'C': 32, 'kernel': 'rbf'}, {'C': 32, 'kernel': 'linear'}, {'C': 32, 'kernel': 'sigmoid'}, {'C': 33, 'kernel': 'rbf'}, {'C': 33, 'kernel': 'linear'}, {'C': 33, 'kernel': 'sigmoid'}, {'C': 34, 'kernel': 'rbf'}, {'C': 34, 'kernel': 'linear'}, {'C': 34, 'kernel': 'sigmoid'}, {'C': 35, 'kernel': 'rbf'}, {'C': 35, 'kernel': 'linear'}, {'C': 35, 'kernel': 'sigmoid'}, {'C': 36, 'kernel': 'rbf'}, {'C': 36, 'kernel': 'linear'}, {'C': 36, 'kernel': 'sigmoid'}, {'C': 37, 'kernel': 'rbf'}, {'C': 37, 'kernel': 'linear'}, {'C': 37, 'kernel': 'sigmoid'}, {'C': 38, 'kernel': 'rbf'}, {'C': 38, 'kernel': 'linear'}, {'C': 38, 'kernel': 'sigmoid'}, {'C': 39, 'kernel': 'rbf'}, {'C': 39, 'kernel': 'linear'}, {'C': 39, 'kernel': 'sigmoid'}, {'C': 40, 'kernel': 'rbf'}, {'C': 40, 'kernel': 'linear'}, {'C': 40, 'kernel': 'sigmoid'}, {'C': 41, 'kernel': 'rbf'}, {'C': 41, 'kernel': 'linear'}, {'C': 41, 'kernel': 'sigmoid'}, {'C': 42, 'kernel': 'rbf'}, {'C': 42, 'kernel': 'linear'}, {'C': 42, 'kernel': 'sigmoid'}, {'C': 43, 'kernel': 'rbf'}, {'C': 43, 'kernel': 'linear'}, {'C': 43, 'kernel': 'sigmoid'}, {'C': 44, 'kernel': 'rbf'}, {'C': 44, 'kernel': 'linear'}, {'C': 44, 'kernel': 'sigmoid'}, {'C': 45, 'kernel': 'rbf'}, {'C': 45, 'kernel': 'linear'}, {'C': 45, 'kernel': 'sigmoid'}, {'C': 46, 'kernel': 'rbf'}, {'C': 46, 'kernel': 'linear'}, {'C': 46, 'kernel': 'sigmoid'}, {'C': 47, 'kernel': 'rbf'}, {'C': 47, 'kernel': 'linear'}, {'C': 47, 'kernel': 'sigmoid'}, {'C': 48, 'kernel': 'rbf'}, {'C': 48, 'kernel': 'linear'}, {'C': 48, 'kernel': 'sigmoid'}, {'C': 49, 'kernel': 'rbf'}, {'C': 49, 'kernel': 'linear'}, {'C': 49, 'kernel': 'sigmoid'}], 'split0_test_score': array([1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. ,\n",
      "       1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. ,\n",
      "       0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8,\n",
      "       1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. ,\n",
      "       1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. ,\n",
      "       0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8,\n",
      "       1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. ,\n",
      "       1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. ,\n",
      "       0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8,\n",
      "       1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. ,\n",
      "       1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. ,\n",
      "       0.8, 1. , 1. , 0.8]), 'split1_test_score': array([1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. ,\n",
      "       0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8,\n",
      "       1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 0.8, 1. , 0.8, 0.8,\n",
      "       1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 0.8, 1. , 0.8, 0.8, 1. ,\n",
      "       0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8,\n",
      "       0.8, 1. , 0.8, 0.8, 1. , 0.8, 1. , 1. , 0.8, 0.8, 1. , 0.8, 0.8,\n",
      "       1. , 0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8, 1. , 1. , 0.8, 1. , 1. ,\n",
      "       0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8,\n",
      "       1. , 1. , 0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8, 0.8,\n",
      "       1. , 0.8, 0.8, 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. ,\n",
      "       0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8, 0.8, 1. , 0.8, 1. , 1. , 0.8,\n",
      "       0.8, 1. , 0.8, 1. ]), 'split2_test_score': array([1. , 1. , 0.6, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
      "       1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
      "       1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 0.6, 1. , 1. , 0.6,\n",
      "       1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. ,\n",
      "       1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. ,\n",
      "       0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6,\n",
      "       1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. ,\n",
      "       1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. ,\n",
      "       0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6,\n",
      "       1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. ,\n",
      "       1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. , 0.6, 1. , 1. ,\n",
      "       0.6, 1. , 1. , 0.6]), 'split3_test_score': array([1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
      "       1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
      "       1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
      "       1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
      "       1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
      "       1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
      "       1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
      "       1. , 1. , 1. , 1. , 1. , 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. ,\n",
      "       0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8,\n",
      "       1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. ,\n",
      "       1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. , 0.8, 1. , 1. ,\n",
      "       0.8, 1. , 1. , 0.8]), 'split4_test_score': array([1.  , 1.  , 0.75, 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
      "       1.  , 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  ,\n",
      "       1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75,\n",
      "       1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  ,\n",
      "       0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  ,\n",
      "       1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75,\n",
      "       1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  ,\n",
      "       0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  ,\n",
      "       1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75,\n",
      "       1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  ,\n",
      "       0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  ,\n",
      "       1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75,\n",
      "       1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  , 0.75, 1.  , 1.  ,\n",
      "       0.75, 1.  , 1.  , 0.75]), 'mean_test_score': array([1.  , 0.96, 0.83, 1.  , 0.96, 0.96, 1.  , 0.96, 0.96, 1.  , 0.96,\n",
      "       0.96, 1.  , 0.96, 0.91, 1.  , 0.96, 0.91, 1.  , 0.96, 0.91, 1.  ,\n",
      "       0.96, 0.91, 1.  , 0.96, 0.91, 1.  , 0.96, 0.91, 1.  , 0.96, 0.91,\n",
      "       1.  , 0.96, 0.79, 1.  , 0.96, 0.79, 1.  , 0.96, 0.83, 1.  , 0.96,\n",
      "       0.83, 1.  , 0.96, 0.79, 1.  , 0.96, 0.79, 1.  , 0.96, 0.79, 1.  ,\n",
      "       0.96, 0.79, 1.  , 0.96, 0.79, 1.  , 0.96, 0.79, 1.  , 0.96, 0.79,\n",
      "       1.  , 0.96, 0.79, 1.  , 0.96, 0.83, 1.  , 0.96, 0.79, 1.  , 0.96,\n",
      "       0.79, 1.  , 0.96, 0.79, 1.  , 0.96, 0.79, 1.  , 0.96, 0.83, 1.  ,\n",
      "       0.96, 0.83, 1.  , 0.96, 0.79, 1.  , 0.96, 0.79, 1.  , 0.96, 0.75,\n",
      "       1.  , 0.96, 0.75, 1.  , 0.96, 0.79, 1.  , 0.96, 0.75, 1.  , 0.96,\n",
      "       0.75, 1.  , 0.96, 0.75, 1.  , 0.96, 0.75, 1.  , 0.96, 0.75, 1.  ,\n",
      "       0.96, 0.79, 1.  , 0.96, 0.79, 1.  , 0.96, 0.79, 1.  , 0.96, 0.75,\n",
      "       1.  , 0.96, 0.75, 1.  , 0.96, 0.75, 1.  , 0.96, 0.79, 1.  , 0.96,\n",
      "       0.75, 1.  , 0.96, 0.79]), 'std_test_score': array([0.        , 0.08      , 0.15362291, 0.        , 0.08      ,\n",
      "       0.08      , 0.        , 0.08      , 0.08      , 0.        ,\n",
      "       0.08      , 0.08      , 0.        , 0.08      , 0.11135529,\n",
      "       0.        , 0.08      , 0.11135529, 0.        , 0.08      ,\n",
      "       0.11135529, 0.        , 0.08      , 0.11135529, 0.        ,\n",
      "       0.08      , 0.11135529, 0.        , 0.08      , 0.11135529,\n",
      "       0.        , 0.08      , 0.11135529, 0.        , 0.08      ,\n",
      "       0.12806248, 0.        , 0.08      , 0.12806248, 0.        ,\n",
      "       0.08      , 0.15362291, 0.        , 0.08      , 0.15362291,\n",
      "       0.        , 0.08      , 0.12806248, 0.        , 0.08      ,\n",
      "       0.12806248, 0.        , 0.08      , 0.12806248, 0.        ,\n",
      "       0.08      , 0.12806248, 0.        , 0.08      , 0.12806248,\n",
      "       0.        , 0.08      , 0.12806248, 0.        , 0.08      ,\n",
      "       0.12806248, 0.        , 0.08      , 0.12806248, 0.        ,\n",
      "       0.08      , 0.15362291, 0.        , 0.08      , 0.12806248,\n",
      "       0.        , 0.08      , 0.12806248, 0.        , 0.08      ,\n",
      "       0.12806248, 0.        , 0.08      , 0.12806248, 0.        ,\n",
      "       0.08      , 0.15362291, 0.        , 0.08      , 0.15362291,\n",
      "       0.        , 0.08      , 0.12806248, 0.        , 0.08      ,\n",
      "       0.12806248, 0.        , 0.08      , 0.07745967, 0.        ,\n",
      "       0.08      , 0.07745967, 0.        , 0.08      , 0.12806248,\n",
      "       0.        , 0.08      , 0.07745967, 0.        , 0.08      ,\n",
      "       0.07745967, 0.        , 0.08      , 0.07745967, 0.        ,\n",
      "       0.08      , 0.07745967, 0.        , 0.08      , 0.07745967,\n",
      "       0.        , 0.08      , 0.12806248, 0.        , 0.08      ,\n",
      "       0.12806248, 0.        , 0.08      , 0.12806248, 0.        ,\n",
      "       0.08      , 0.07745967, 0.        , 0.08      , 0.07745967,\n",
      "       0.        , 0.08      , 0.07745967, 0.        , 0.08      ,\n",
      "       0.12806248, 0.        , 0.08      , 0.07745967, 0.        ,\n",
      "       0.08      , 0.12806248]), 'rank_test_score': array([  1,  50, 109,   1,  50,  50,   1,  50,  50,   1,  50,  50,   1,\n",
      "        50, 102,   1,  50, 102,   1,  50, 102,   1,  50, 102,   1,  50,\n",
      "       102,   1,  50, 102,   1,  50, 102,   1,  50, 115,   1,  50, 115,\n",
      "         1,  50, 109,   1,  50, 109,   1,  50, 115,   1,  50, 115,   1,\n",
      "        50, 115,   1,  50, 115,   1,  50, 115,   1,  50, 115,   1,  50,\n",
      "       115,   1,  50, 115,   1,  50, 109,   1,  50, 115,   1,  50, 115,\n",
      "         1,  50, 115,   1,  50, 115,   1,  50, 109,   1,  50, 109,   1,\n",
      "        50, 115,   1,  50, 115,   1,  50, 137,   1,  50, 137,   1,  50,\n",
      "       115,   1,  50, 137,   1,  50, 137,   1,  50, 137,   1,  50, 137,\n",
      "         1,  50, 137,   1,  50, 115,   1,  50, 115,   1,  50, 115,   1,\n",
      "        50, 137,   1,  50, 137,   1,  50, 137,   1,  50, 115,   1,  50,\n",
      "       137,   1,  50, 115], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = { \"kernel\": [\"rbf\", \"linear\", \"sigmoid\"], \"C\": range(1,50)}\n",
    "clf = GridSearchCV(svm.SVC(), parameters)\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "print(clf.cv_results_)\n",
    "\n",
    "# TODO: handle overfitting, with cross validation and folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_966226/3737951887.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Performance metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/feature-engineering-i-Acv69h-py3.8/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# delegate only on instances, not the classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/feature-engineering-i-Acv69h-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_estimator_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;31m# raise an AttributeError if `attr` does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# raise an AttributeError if `attr` does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/feature-engineering-i-Acv69h-py3.8/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# delegate only on instances, not the classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/feature-engineering-i-Acv69h-py3.8/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    794\u001b[0m                 \u001b[0;34m\"predict_proba is not available when  probability=False\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             )\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# Performance metrics\n",
    "\n",
    "prediction = clf.predict(test_X)\n",
    "accuracy = accuracy_score(test_Y, prediction)\n",
    "print(accuracy)\n",
    "\n",
    "confusion_matrix(test_Y, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (1183308413.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_226131/1183308413.py\"\u001b[0;36m, line \u001b[0;32m34\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameter Tuning\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live demo parsing\n",
    "\n",
    "A second part, we unfortunately had no time to implement, is **live demo parsing**.\n",
    "\n",
    "We need to start by creating a probability N by N matrix, with N the different states.\n",
    "This is also called a ** stochastic matrix**. Each combination of a row(x) and a column(y) is the probability to go from stateX to stateY.\n",
    "\n",
    "Since we eventually want to find the winner of a game we also need something called absorbing states. **An absorbing state is a state that, once entered, cannot be left**\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1662b782f29f5d594b458e92dae39042b29e0bba41ca088e4788afc70c25741"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('feature-engineering-i-Acv69h-py3.8': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
